{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7258d113-3467-40d0-8e08-4a34f853d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze.analyze import AggregateCheckpoints\n",
    "from models.models import model_setup_DER, model_setup_DE\n",
    "from data.data import DataPreparation\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a2cbb-05b3-4342-b332-61b0110f12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title_lookup = {'predictive': 'output uncert', 'feature': 'input uncert'}\n",
    "new_title_lookup = {'predictive': 'output', 'feature': 'input'}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoints = AggregateCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3696760-d5ab-4b8d-8dcb-acc151f2551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = True\n",
    "prescription = \"linear_homoskedastic\"\n",
    "inject_type_list = [\"predictive\", \"feature\"]\n",
    "data_dim_list = [\"0D\", \"2D\"]\n",
    "model_type = [\"DE\", \"DER\"]\n",
    "noise_list = [\"low\", \"medium\", \"high\"]\n",
    "\n",
    "'''\n",
    "inject_type_list = [\"predictive\"]\n",
    "data_dim_list = [\"2D\"]\n",
    "model_type = [\"DE\"]\n",
    "noise_list = [\"low\"]\n",
    "'''\n",
    "\n",
    "\n",
    "# these are the three colors for the three noise levels\n",
    "color_list = [\"#DFA316\", \"#339989\", \"#ED6A5A\", \"#292F36\"]\n",
    "size_df_linear = 10000 # 1000\n",
    "size_df_image = 175000\n",
    "epoch = 99\n",
    "ensemble = True\n",
    "n_models = 15\n",
    "\n",
    "mega_dict = {}\n",
    "\n",
    "# Nested loops to fill the dictionary\n",
    "for noise in noise_list:\n",
    "    mega_dict[noise] = {}  # Create a sub-dictionary for each noise level\n",
    "    for model in model_type:\n",
    "        mega_dict[noise][model] = {}  # Create a sub-dictionary for each model type\n",
    "        for dim in data_dim_list:\n",
    "            mega_dict[noise][model][dim] = {}  # Create a sub-dictionary for each data dimension\n",
    "            for inject_type in inject_type_list:\n",
    "                mega_dict[noise][model][dim][inject_type] = []\n",
    "\n",
    "sigma_y_lookup = {'low': 0.01, 'medium': 0.05, 'high': 0.10}\n",
    "for n, noise in enumerate(noise_list):\n",
    "    for m, model in enumerate(model_type):\n",
    "        for j, dim in enumerate(data_dim_list):\n",
    "            for i, inject_type in enumerate(inject_type_list):\n",
    "\n",
    "                chk = 0\n",
    "                \n",
    "                # make the test set\n",
    "                data = DataPreparation()\n",
    "                \n",
    "                if dim == \"0D\":\n",
    "                    data.sample_params_from_prior(size_df_linear)\n",
    "                    if inject_type == \"feature\":\n",
    "                        data.simulate_data(\n",
    "                            data.params,\n",
    "                            noise,\n",
    "                            \"linear_homoskedastic\",\n",
    "                            inject_type=inject_type,\n",
    "                            seed=41,\n",
    "                            vary_sigma=True,\n",
    "                        )\n",
    "                    else:\n",
    "                        sigma = DataPreparation.get_sigma(\n",
    "                            noise, inject_type=inject_type, data_dimension=dim)\n",
    "                        data.simulate_data(\n",
    "                            data.params,\n",
    "                            sigma,\n",
    "                            \"linear_homoskedastic\",\n",
    "                            inject_type=inject_type,\n",
    "                            seed=41,\n",
    "                        )\n",
    "                    df_array = data.get_dict()\n",
    "                    df = {key: torch.tensor(value) if not isinstance(value, TensorDataset) else value for key, value in df_array.items()}\n",
    "                    len_df = len(df[\"params\"][:, 0].numpy())\n",
    "                    len_x = np.shape(df[\"output\"])[1]\n",
    "                    ms_array = np.repeat(df[\"params\"][:, 0].numpy(), len_x)\n",
    "                    bs_array = np.repeat(df[\"params\"][:, 1].numpy(), len_x)\n",
    "                    xs_array = np.reshape(df[\"inputs\"].numpy(), (len_df * len_x))\n",
    "                    ys_array = np.reshape(df[\"output\"].numpy(), (len_df * len_x))\n",
    "                    inputs = np.array([xs_array, ms_array, bs_array]).T\n",
    "                    model_inputs = inputs\n",
    "                    model_outputs = ys_array\n",
    "                elif dim == \"2D\":\n",
    "                    sigma = DataPreparation.get_sigma(\n",
    "                        noise, inject_type=inject_type, data_dimension=dim)\n",
    "                    data.sample_params_from_prior(\n",
    "                        size_df_image,\n",
    "                        low=[0, 1, -1.5],\n",
    "                        high=[0.01, 10, 1.5],\n",
    "                        n_params=3,\n",
    "                        seed=41)\n",
    "                    model_inputs, model_outputs = data.simulate_data_2d(\n",
    "                        size_df_image,\n",
    "                        data.params,\n",
    "                        image_size=32,\n",
    "                        inject_type=inject_type,\n",
    "                        sigma=sigma)\n",
    "                if uniform:\n",
    "                    model_inputs, model_outputs = DataPreparation.select_uniform(\n",
    "                        model_inputs, model_outputs, dim, verbose=False, rs=40\n",
    "                    )\n",
    "                x_test = model_inputs\n",
    "                y_test = model_outputs\n",
    "                \n",
    "                path = \"../DeepUQResources/checkpoints/\"\n",
    "                if model == \"DER\":\n",
    "                    setupmodel, lossFn = model_setup_DER(\n",
    "                        model, DEVICE, n_hidden=64, data_type=dim)\n",
    "                    COEFF = 0.01\n",
    "                    file_name = (\n",
    "                        str(path)\n",
    "                        + f\"{model}_{prescription}_{inject_type}_{dim}\"\n",
    "                        + f\"_noise_{noise}_loss_DER_COEFF_{COEFF}_epoch_{epoch}\"\n",
    "                    )\n",
    "                    if dim == \"0D\":\n",
    "                        file_name += f\"_sizedf_{size_df_linear}\"\n",
    "                    elif dim == \"2D\":\n",
    "                        file_name += f\"_sizedf_{size_df_image}\"\n",
    "                    file_name += \".pt\"\n",
    "                    try:\n",
    "                        #print('loading this file', file_name)\n",
    "                        chk = torch.load(file_name, map_location=DEVICE)\n",
    "                    except FileNotFoundError:\n",
    "                        #print(\"cannot find this model\", file_name)\n",
    "                        continue\n",
    "                    setupmodel.load_state_dict(chk.get(\"model_state_dict\"))\n",
    "                    setupmodel.eval()\n",
    "\n",
    "                    y_pred = setupmodel(torch.Tensor(x_test)).detach().numpy()\n",
    "                    beta = y_pred[:, 3]\n",
    "                    nu = y_pred[:, 1]\n",
    "                    alpha = y_pred[:, 2]\n",
    "                    u_al = np.sqrt(abs(beta * (1 + nu) / (alpha * nu)))\n",
    "                    \n",
    "                    \n",
    "                elif model == \"DE\":\n",
    "                    models_used = 0\n",
    "                    loss = \"bnll_loss\"\n",
    "                    setupmodel, lossFn = model_setup_DE(\n",
    "                        loss, DEVICE, n_hidden=64, data_type=dim)\n",
    "                    BETA = 0.5\n",
    "                    u_al = []\n",
    "                    for m in range(n_models):\n",
    "                        if models_used > 9:\n",
    "                            break\n",
    "                        file_name = (\n",
    "                            str(path) +\n",
    "                            f\"{model}_{prescription}_{inject_type}_{dim}\"\n",
    "                            f\"_noise_{noise}_beta_{BETA}_nmodel_{m}_epoch_{epoch}\"\n",
    "                        )\n",
    "                        if dim == \"0D\":\n",
    "                            file_name += f\"_sizedf_{size_df_linear}\"\n",
    "                        elif dim == \"2D\":\n",
    "                            file_name += f\"_sizedf_{size_df_image}\"\n",
    "                        file_name += \".pt\"\n",
    "                        try:\n",
    "                            #print('loading this file', file_name)\n",
    "                            chk = torch.load(file_name, map_location=DEVICE)\n",
    "                        except FileNotFoundError:\n",
    "                            # print(\"cannot find this model\", file_name)\n",
    "                            continue\n",
    "                        setupmodel.load_state_dict(chk.get(\"model_state_dict\"))\n",
    "                        setupmodel.eval()\n",
    "                        y_pred = setupmodel(torch.Tensor(x_test)).detach().numpy()\n",
    "                        # for some reason if the model fails it predicts\n",
    "                        # really large values for sigma\n",
    "                        \n",
    "                        if np.all(y_pred[:, 1] == y_pred[0, 1]) or np.mean(np.sqrt(y_pred[:, 1])) > 0.2:\n",
    "                            # All values are the same\n",
    "                            print(\"All values in y_pred[:,1] are the same or they are really high\")\n",
    "                            # then we need to skip this model\n",
    "                            print('not using this model ', m)\n",
    "                            continue\n",
    "                        else:\n",
    "                            '''\n",
    "                            plt.clf()\n",
    "                            plt.hist(np.sqrt(y_pred[:, 1]), bins=100)\n",
    "                            plt.title(f'model m {m}')\n",
    "                            plt.show()\n",
    "                            '''\n",
    "                            print('using this model', m)\n",
    "                            models_used += 1\n",
    "                            #print('using this model ', m)            \n",
    "                        u_al_one = np.sqrt(y_pred[:, 1])\n",
    "                        u_al.append(u_al_one)\n",
    "\n",
    "                        \n",
    "                # populate the mega dict\n",
    "                mega_dict[noise][model][dim][inject_type] = u_al\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e49391-bf21-4c96-a2b6-8206458fe262",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mega dict', mega_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16be1c4-cd6d-4a95-b658-72d222722204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# suppress seaborn/pandas specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Example setup, use your actual data/model outputs\n",
    "noise_list = [\"low\", \"medium\", \"high\"]\n",
    "model_type = [\"DE\", \"DER\"]\n",
    "inject_type_list = [\"predictive\", \"feature\"]\n",
    "data_dim_list = [\"0D\", \"2D\"]\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(1, len(model_type) * len(noise_list), figsize=(20, 3.5))\n",
    "axes = axes.flatten()\n",
    "index = 0\n",
    "\n",
    "sigma_y_lookup = {'low': 0.01, 'medium': 0.05, 'high': 0.10}\n",
    "palette = sns.color_palette(\"Paired\", n_colors=len(data_dim_list) * len(inject_type_list))\n",
    "\n",
    "# Define x-axis limits for each noise level\n",
    "x_limits = {\n",
    "    \"low\": (0, 0.05),\n",
    "    \"medium\": (0, 0.1),\n",
    "    \"high\": (0, 0.12)\n",
    "}\n",
    "\n",
    "for n, noise in enumerate(noise_list):\n",
    "    for m, model in enumerate(model_type):\n",
    "        ax = axes[index]\n",
    "        \n",
    "        y_offset = 0  # Initialize a consistent y_offset\n",
    "        kde_max = 0  # Track the maximum y-value across all KDE plots\n",
    "        \n",
    "        # Collect KDE data to plot\n",
    "        kde_data = []\n",
    "        for j, dim in enumerate(data_dim_list):\n",
    "            for i, inject_type in enumerate(inject_type_list):\n",
    "                # Generate or load aleatoric uncertainty data (replace with your own logic)\n",
    "                u_al_data = mega_dict[noise][model][dim][inject_type]\n",
    "                \n",
    "                \n",
    "                # Stack the DEs\n",
    "                if model == \"DE\":\n",
    "                    combined_array = np.concatenate(u_al_data)\n",
    "                elif model == \"DER\":\n",
    "                    combined_array = u_al_data\n",
    "                \n",
    "                # Store KDE data\n",
    "                kde_data.append((combined_array, palette[j*len(inject_type_list)+i], f\"{new_title_lookup[inject_type]} - {dim}\"))\n",
    "        \n",
    "        # Plot KDEs in reverse order\n",
    "        for combined_array, color, label in reversed(kde_data):\n",
    "            '''\n",
    "            kde = sns.kdeplot(combined_array, fill=True, bw_adjust=0.5, alpha=0.75, ax=ax,\n",
    "                              clip_on=False, color=color, label=label)\n",
    "\n",
    "            # Retrieve the KDE data\n",
    "            x = kde.lines[0].get_data()[0]\n",
    "            y = kde.lines[0].get_data()[1]\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Clear the previous KDE plot\n",
    "            ax.clear()\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_normalized, color='blue', alpha=0.75)\n",
    "            ax.plot(x, y_normalized, color='blue', label='Normalized KDE')\n",
    "            '''\n",
    "            # Compute KDE\n",
    "            kde = gaussian_kde(combined_array, bw_method=0.1)  # Adjust bw_method as needed\n",
    "            \n",
    "            # Define range of x values\n",
    "            x = np.linspace(min(combined_array), max(combined_array), 1000)\n",
    "            \n",
    "            # Evaluate KDE over x values\n",
    "            y = kde(x)\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_offset, y_normalized + y_offset, color=color, alpha=0.75)\n",
    "            ax.plot(x, y_normalized + y_offset, color=color, label=label)\n",
    "            \n",
    "            '''\n",
    "            # Find the maximum y-value and adjust offsets\n",
    "            if kde.collections:\n",
    "                paths = kde.collections[-1].get_paths()\n",
    "                for path in paths:\n",
    "                    vertices = path.vertices\n",
    "                    vertices[:, 1] += y_offset  # Offset the y-values of the vertices\n",
    "                    kde_max = vertices[:, 1].max() / 1.5\n",
    "            '''\n",
    "            ax.scatter(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                color='black', edgecolor='black', zorder=100)\n",
    "            \n",
    "            ax.errorbar(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                xerr = 3*np.std(combined_array),\n",
    "                color='grey', capsize=5)\n",
    "            ax.errorbar(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                xerr = np.std(combined_array),\n",
    "                color='black', capsize=5)\n",
    "            y_offset += 0.25\n",
    "\n",
    "        # Set title and limits\n",
    "        #ax.set_title(f'{model} - {noise} noise')\n",
    "        ax.set_yticks([])  # Hide y-ticks\n",
    "        ax.set_ylim(0, y_offset+0.25)  # Adjust y-limits based on the max y_offset\n",
    "        \n",
    "        # Set x-axis limits after plotting\n",
    "        ax.set_xlim(x_limits[noise])\n",
    "\n",
    "        # Add vertical line indicating sigma_y for reference\n",
    "        if noise == \"low\":\n",
    "            ax.axvline(x=0.01, color='grey', ls='--')\n",
    "        elif noise == \"medium\":\n",
    "            ax.axvline(x=0.05, color='grey', ls='--')\n",
    "        elif noise == \"high\":\n",
    "            ax.axvline(x=0.10, color='grey', ls='--')\n",
    "        \n",
    "        # Only add the legend on the first subplot\n",
    "        if index == 0:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(handles[::-1], labels[::-1], loc='upper right')  # Reverse the order of the legend\n",
    "        else:\n",
    "            ax.legend().remove()  # Remove the legend from all other subplots\n",
    "        ax.set_yticklabels([])\n",
    "        index += 1\n",
    "\n",
    "axes[0].set_xlim([0, 0.06])\n",
    "axes[1].set_xlim([0, 0.03])\n",
    "axes[2].set_xlim([0.01, 0.09])\n",
    "axes[3].set_xlim([0.01, 0.07])\n",
    "axes[4].set_xlim([0.01, 0.13])\n",
    "axes[5].set_xlim([0.01, 0.13])\n",
    "\n",
    "axes[0].set_xlim([-0.01, 0.06])\n",
    "axes[1].set_xlim([-0.01, 0.06])\n",
    "axes[2].set_xlim([0.01, 0.08])\n",
    "axes[3].set_xlim([0.01, 0.08])\n",
    "axes[4].set_xlim([0.04, 0.11])\n",
    "axes[5].set_xlim([0.04, 0.11])\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[3].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[4].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[5].tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "#axes[0].set_xlabel(r'$\\sigma_{al}$')\n",
    "plt.subplots_adjust(wspace=0)\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../../../Desktop/sigma_in_sigma_out_ridgeplot_ensemble_{n_models}_uniform.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacdab8-4e2e-4828-b3bd-d51c7a9ff68b",
   "metadata": {},
   "source": [
    "Create a version of this that has only two panels; one for DER and one for DE and puts all three noise levels on each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e98f53b-2969-4ef7-9c07-ee1ceb851ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# suppress seaborn/pandas specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Example setup, use your actual data/model outputs\n",
    "noise_list = [\"low\", \"medium\", \"high\"]\n",
    "model_type = [\"DE\", \"DER\"]\n",
    "inject_type_list = [\"predictive\", \"feature\"]\n",
    "data_dim_list = [\"0D\", \"2D\"]\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(1, len(model_type), figsize=(20, 3.5))\n",
    "axes = axes.flatten()\n",
    "index = 0\n",
    "\n",
    "sigma_y_lookup = {'low': 0.01, 'medium': 0.05, 'high': 0.10}\n",
    "palette = sns.color_palette(\"Paired\", n_colors=len(data_dim_list) * len(inject_type_list))\n",
    "# these are colors for the low medium and high noise level\n",
    "palette_list = ['#A2C5AC', '#9DB5B2', '#878E99', '#7F6A93']\n",
    "palette_list = ['#86CB92', '#71B48D', '#404E7C', '#251F47']\n",
    "# lighter version of the above\n",
    "#palette_list = ['#C6E7CB', '#A1CEB4', '#A1ABCE', '#8A7FC7']\n",
    "\n",
    "# Define x-axis limits for each noise level\n",
    "x_limits = {\n",
    "    \"low\": (0, 0.05),\n",
    "    \"medium\": (0, 0.1),\n",
    "    \"high\": (0, 0.12)\n",
    "}\n",
    "\n",
    "\n",
    "for m, model in enumerate(model_type):\n",
    "    ax = axes[index]\n",
    "    for n, noise in enumerate(noise_list):\n",
    "        \n",
    "        y_offset = 0  # Initialize a consistent y_offset\n",
    "        kde_max = 0  # Track the maximum y-value across all KDE plots\n",
    "        \n",
    "        # Collect KDE data to plot\n",
    "        kde_data = []\n",
    "        color_twerk = 0\n",
    "        for j, dim in enumerate(data_dim_list):\n",
    "            for i, inject_type in enumerate(inject_type_list):\n",
    "                palette = sns.dark_palette(palette_list[color_twerk], reverse=True)#, as_cmap=True)\n",
    "                color_twerk +=1\n",
    "                # Generate or load aleatoric uncertainty data (replace with your own logic)\n",
    "                u_al_data = mega_dict[noise][model][dim][inject_type]\n",
    "                \n",
    "                \n",
    "                # Stack the DEs\n",
    "                if model == \"DE\":\n",
    "                    combined_array = np.concatenate(u_al_data)\n",
    "                elif model == \"DER\":\n",
    "                    combined_array = u_al_data\n",
    "                \n",
    "                # Store KDE data\n",
    "                kde_data.append((combined_array, palette[int(n)], f\"{new_title_lookup[inject_type]}, {dim}\"))\n",
    "                \n",
    "        \n",
    "        # Plot KDEs in reverse order\n",
    "        for combined_array, color, label in reversed(kde_data):\n",
    "            '''\n",
    "            kde = sns.kdeplot(combined_array, fill=True, bw_adjust=0.5, alpha=0.75, ax=ax,\n",
    "                              clip_on=False, color=color, label=label)\n",
    "\n",
    "            # Retrieve the KDE data\n",
    "            x = kde.lines[0].get_data()[0]\n",
    "            y = kde.lines[0].get_data()[1]\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Clear the previous KDE plot\n",
    "            ax.clear()\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_normalized, color='blue', alpha=0.75)\n",
    "            ax.plot(x, y_normalized, color='blue', label='Normalized KDE')\n",
    "            '''\n",
    "            # Compute KDE\n",
    "            kde = gaussian_kde(combined_array, bw_method=0.05)  # Adjust bw_method as needed\n",
    "            \n",
    "            # Define range of x values\n",
    "            x = np.linspace(min(combined_array), max(combined_array), 1000)\n",
    "            \n",
    "            # Evaluate KDE over x values\n",
    "            y = kde(x)\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_offset, y_normalized + y_offset, color=color, alpha=0.75)\n",
    "            ax.plot(x, y_normalized + y_offset, color=color, label=label)\n",
    "            if n == 0:\n",
    "                ax.annotate(label, xy=(-0.007, y_offset+0.07), size=15)\n",
    "            ax.scatter(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                color='black', edgecolor='black', zorder=100)\n",
    "            ax.errorbar(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                xerr = np.std(combined_array),\n",
    "                color='black', capsize=5)\n",
    "            y_offset += 0.25\n",
    "\n",
    "        # Set title and limits\n",
    "        #ax.set_title(f'{model} - {noise} noise')\n",
    "        ax.set_yticks([])  # Hide y-ticks\n",
    "        ax.set_ylim(0, y_offset+0.25)  # Adjust y-limits based on the max y_offset\n",
    "        \n",
    "        # Set x-axis limits after plotting\n",
    "        ax.set_xlim(x_limits[noise])\n",
    "\n",
    "        # Add vertical line indicating sigma_y for reference\n",
    "        if noise == \"low\":\n",
    "            ax.axvline(x=0.01, color='black', ls='--')\n",
    "        elif noise == \"medium\":\n",
    "            ax.axvline(x=0.05, color='black', ls='--')\n",
    "        elif noise == \"high\":\n",
    "            ax.axvline(x=0.10, color='black', ls='--')\n",
    "        '''\n",
    "        # Only add the legend on the first subplot\n",
    "        if index == 0:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(handles[::-1], labels[::-1], loc='upper right')  # Reverse the order of the legend\n",
    "        else:\n",
    "        '''\n",
    "        ax.legend().remove()  # Remove the legend from all other subplots\n",
    "        ax.set_yticklabels([])\n",
    "    index += 1\n",
    "\n",
    "axes[0].set_xlim([-0.008, 0.11])\n",
    "axes[1].set_xlim([-0.008, 0.11])\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=14)\n",
    "axes[0].set_title('Deep Ensemble (DE) experiments', size=15)\n",
    "axes[1].set_title('Deep Evidential Regression (DER) experiments', size=15)\n",
    "\n",
    "#axes[0].set_xlabel(r'$\\sigma_{al}$')\n",
    "plt.subplots_adjust(wspace=0)\n",
    "fig.supxlabel(r'Predicted Aleatoric Uncertainty, $\\sigma_{al}$', size=15)\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../../../Desktop/sigma_in_sigma_out_ridgeplot_ensemble_two_panel_{n_models}_uniform.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e227e-37b8-44b6-98f2-299f7c8b169a",
   "metadata": {},
   "source": [
    "Making a version where the color is for the noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101d2b9-dc45-4235-9fd2-504a083d2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# suppress seaborn/pandas specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Example setup, use your actual data/model outputs\n",
    "noise_list = [\"low\", \"medium\", \"high\"]\n",
    "model_type = [\"DE\", \"DER\"]\n",
    "inject_type_list = [\"predictive\", \"feature\"]\n",
    "data_dim_list = [\"0D\", \"2D\"]\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(1, len(model_type), figsize=(20, 4))\n",
    "axes = axes.flatten()\n",
    "index = 0\n",
    "\n",
    "sigma_y_lookup = {'low': 0.01, 'medium': 0.05, 'high': 0.10}\n",
    "color_noise = ['#FFC2E8', '#FF47B9', '#66003F']#'#B80071']\n",
    "#color_noise = ['#C5C0EC', '#6F62D0', '#3C2F9D']\n",
    "\n",
    "# Define x-axis limits for each noise level\n",
    "x_limits = {\n",
    "    \"low\": (0, 0.05),\n",
    "    \"medium\": (0, 0.1),\n",
    "    \"high\": (0, 0.12)\n",
    "}\n",
    "\n",
    "\n",
    "for m, model in enumerate(model_type):\n",
    "    ax = axes[index]\n",
    "    for n, noise in enumerate(noise_list):\n",
    "        \n",
    "        y_offset = 0  # Initialize a consistent y_offset\n",
    "        kde_max = 0  # Track the maximum y-value across all KDE plots\n",
    "        \n",
    "        # Collect KDE data to plot\n",
    "        kde_data = []\n",
    "        color_twerk = 0\n",
    "        for j, dim in enumerate(data_dim_list):\n",
    "            for i, inject_type in enumerate(inject_type_list):\n",
    "                # Generate or load aleatoric uncertainty data (replace with your own logic)\n",
    "                u_al_data = mega_dict[noise][model][dim][inject_type]\n",
    "                \n",
    "                \n",
    "                # Stack the DEs\n",
    "                if model == \"DE\":\n",
    "                    combined_array = np.concatenate(u_al_data)\n",
    "                elif model == \"DER\":\n",
    "                    combined_array = u_al_data\n",
    "                \n",
    "                # Store KDE data\n",
    "                kde_data.append((combined_array, f\"{dim}, {new_title_lookup[inject_type]}\"))\n",
    "                \n",
    "        \n",
    "        # Plot KDEs in reverse order\n",
    "        for combined_array, label in reversed(kde_data):\n",
    "            '''\n",
    "            kde = sns.kdeplot(combined_array, fill=True, bw_adjust=0.5, alpha=0.75, ax=ax,\n",
    "                              clip_on=False, color=color, label=label)\n",
    "\n",
    "            # Retrieve the KDE data\n",
    "            x = kde.lines[0].get_data()[0]\n",
    "            y = kde.lines[0].get_data()[1]\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Clear the previous KDE plot\n",
    "            ax.clear()\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_normalized, color='blue', alpha=0.75)\n",
    "            ax.plot(x, y_normalized, color='blue', label='Normalized KDE')\n",
    "            '''\n",
    "            # Compute KDE\n",
    "            kde = gaussian_kde(combined_array, bw_method=0.05)  # Adjust bw_method as needed\n",
    "            \n",
    "            # Define range of x values\n",
    "            x = np.linspace(min(combined_array), max(combined_array), 1000)\n",
    "            \n",
    "            # Evaluate KDE over x values\n",
    "            y = kde(x)\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_offset, y_normalized + y_offset, color=color_noise[n], alpha=0.25)\n",
    "            ax.plot(x, y_normalized + y_offset, color=color_noise[n], label=label)\n",
    "            if n == 0 and m == 0:\n",
    "                #transform = ax.get_xaxis_trasform()\n",
    "                #ann = ax.annotate(label, xy=(-0.07, y_offset+0.07), xycoords=transform, size=20)\n",
    "                ax.annotate(label, xy=(-0.013, y_offset+0.07), size=20, annotation_clip=False)\n",
    "            ax.scatter(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                color=color_noise[n], edgecolor='black', zorder=100)\n",
    "            ax.errorbar(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                xerr = np.std(combined_array),\n",
    "                color='black', capsize=5)\n",
    "            #y_offset += 0.25\n",
    "            y_offset += 0.27\n",
    "\n",
    "        # Set title and limits\n",
    "        #ax.set_title(f'{model} - {noise} noise')\n",
    "        ax.set_yticks([])  # Hide y-ticks\n",
    "        #ax.set_ylim(0, y_offset+0.25)  # Adjust y-limits based on the max y_offset\n",
    "        ax.set_ylim(0, y_offset+0.3)\n",
    "        \n",
    "        # Set x-axis limits after plotting\n",
    "        ax.set_xlim(x_limits[noise])\n",
    "\n",
    "        # Add vertical line indicating sigma_y for reference\n",
    "        if noise == \"low\":\n",
    "            ax.axvline(x=0.01, color=color_noise[n], ls='--')\n",
    "        elif noise == \"medium\":\n",
    "            ax.axvline(x=0.05, color=color_noise[n], ls='--')\n",
    "        elif noise == \"high\":\n",
    "            ax.axvline(x=0.10, color=color_noise[n], ls='--')\n",
    "        '''\n",
    "        # Only add the legend on the first subplot\n",
    "        if index == 0:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(handles[::-1], labels[::-1], loc='upper right')  # Reverse the order of the legend\n",
    "        else:\n",
    "        '''\n",
    "        ax.set_xticks([0.01, 0.05, 0.1])\n",
    "        ax.set_xticklabels([0.01, 0.05, 0.10])\n",
    "        ax.legend().remove()  # Remove the legend from all other subplots\n",
    "        ax.set_yticklabels([])\n",
    "    index += 1\n",
    "\n",
    "axes[0].set_xlim([0.005, 0.11])\n",
    "axes[1].set_xlim([0.005, 0.11])\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "axes[0].set_title('Deep Ensemble (DE)', size=20)\n",
    "axes[1].set_title('Deep Evidential Regression (DER)', size=20)\n",
    "\n",
    "#axes[0].set_xlabel(r'$\\sigma_{al}$')\n",
    "#plt.subplots_adjust(wspace=0)\n",
    "fig.supxlabel(r'Predicted Aleatoric Uncertainty, $\\sigma_{al}$', size=20, y=0.05)\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../../../Desktop/sigma_in_sigma_out_ridgeplot_ensemble_two_panel_noise_color_{n_models}_uniform.png',\n",
    "    dpi=1000,\n",
    "    bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
